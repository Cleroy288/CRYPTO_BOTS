{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Vérification des données pour historical_data_eth_1M.csv...\n",
      "✅ Données chargées : 3802749 lignes.\n",
      "❌ 8632 timestamps manquants détectés.\n",
      "\n",
      "--- Résumé des problèmes détectés ---\n",
      "  - Missing data: 8632 timestamps manquants.\n",
      "\n",
      "✅ Validation terminée. Aucun problème majeur détecté.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def validate_data_integrity(file_name, symbol, interval, expected_currency):\n",
    "    \"\"\"\n",
    "    Valide l'intégrité des données dans un fichier CSV.\n",
    "    \n",
    "    :param file_name: Nom du fichier CSV contenant les données.\n",
    "    :param symbol: Le symbole attendu (ex: \"ETHUSDT\").\n",
    "    :param interval: Intervalle attendu des timestamps (ex: \"1min\").\n",
    "    :param expected_currency: Monnaie attendue (ex: \"ETH\").\n",
    "    :return: Un dictionnaire contenant les résultats des vérifications.\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Vérification des données pour {file_name}...\")\n",
    "\n",
    "    # Chargement des données\n",
    "    try:\n",
    "        df = pd.read_csv(file_name, parse_dates=['timestamp'], index_col='timestamp')\n",
    "        print(f\"✅ Données chargées : {len(df)} lignes.\")\n",
    "    except FileNotFoundError:\n",
    "        return {\"status\": \"error\", \"message\": f\"Fichier introuvable : {file_name}\"}\n",
    "    except pd.errors.EmptyDataError:\n",
    "        return {\"status\": \"error\", \"message\": f\"Fichier vide ou mal formaté : {file_name}\"}\n",
    "\n",
    "    results = {\"status\": \"success\", \"issues\": []}\n",
    "\n",
    "    # Vérification de la monnaie (optionnelle si incluse dans les données)\n",
    "    if \"symbol\" in df.columns and not all(df[\"symbol\"] == symbol):\n",
    "        results[\"issues\"].append(\"Currency mismatch: Le symbole ne correspond pas aux données.\")\n",
    "        print(f\"❌ Currency mismatch : {symbol} attendu, mais les données contiennent d'autres symboles.\")\n",
    "\n",
    "    # Vérification des doublons\n",
    "    if df.index.duplicated().any():\n",
    "        results[\"issues\"].append(\"Duplicate timestamps: Les données contiennent des doublons.\")\n",
    "        print(\"❌ Doublons détectés dans les données.\")\n",
    "\n",
    "    # Vérification de l'ordre\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        results[\"issues\"].append(\"Unsorted data: Les données ne sont pas triées.\")\n",
    "        print(\"❌ Les données ne sont pas triées.\")\n",
    "\n",
    "    # Vérification des timestamps manquants\n",
    "    start_date = df.index.min()\n",
    "    end_date = df.index.max()\n",
    "    complete_index = pd.date_range(start=start_date, end=end_date, freq=interval)\n",
    "    missing_timestamps = complete_index.difference(df.index)\n",
    "\n",
    "    if len(missing_timestamps) > 0:\n",
    "        results[\"issues\"].append(f\"Missing data: {len(missing_timestamps)} timestamps manquants.\")\n",
    "        print(f\"❌ {len(missing_timestamps)} timestamps manquants détectés.\")\n",
    "    else:\n",
    "        print(\"✅ Aucun timestamp manquant détecté.\")\n",
    "\n",
    "    # Vérification du timestamp correct\n",
    "    if len(df) > 0:\n",
    "        first_timestamp = df.index.min()\n",
    "        last_timestamp = df.index.max()\n",
    "\n",
    "        if first_timestamp != complete_index[0] or last_timestamp != complete_index[-1]:\n",
    "            results[\"issues\"].append(\"Timestamp mismatch: Les timestamps ne correspondent pas à l'intervalle attendu.\")\n",
    "            print(f\"❌ Les timestamps des données ({first_timestamp} -> {last_timestamp}) ne correspondent pas à l'intervalle attendu.\")\n",
    "\n",
    "    if not results[\"issues\"]:\n",
    "        print(\"✅ Toutes les vérifications ont été passées avec succès.\")\n",
    "    else:\n",
    "        print(\"\\n--- Résumé des problèmes détectés ---\")\n",
    "        for issue in results[\"issues\"]:\n",
    "            print(f\"  - {issue}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "file_name = \"historical_data_eth_1M.csv\"\n",
    "symbol = \"ETHUSDT\"\n",
    "interval = \"1min\"\n",
    "expected_currency = \"ETH\"\n",
    "\n",
    "results = validate_data_integrity(file_name, symbol, interval, expected_currency)\n",
    "\n",
    "if results[\"status\"] == \"success\":\n",
    "    print(\"\\n✅ Validation terminée. Aucun problème majeur détecté.\")\n",
    "else:\n",
    "    print(\"\\n❌ Validation échouée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Tri des données dans historical_data_eth_1M.csv...\n",
      "✅ Données chargées : 3802749 lignes.\n",
      "✅ Tri effectué.\n",
      "💾 Réécriture des données triées dans historical_data_eth_1M.csv...\n",
      "✅ Réécriture terminée.\n",
      "✅ Fichier trié et réécrit : historical_data_eth_1M.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\"\"\"\n",
    "code utilisé pour trier la base de donnée \n",
    "\"\"\"\n",
    "\n",
    "def sort_csv_in_place(file_name):\n",
    "    \"\"\"\n",
    "    Trie un fichier CSV par colonne de timestamp, de la plus ancienne à la plus récente,\n",
    "    et réécrit le fichier d'origine avec les données triées.\n",
    "\n",
    "    :param file_name: Nom du fichier CSV à trier.\n",
    "    \"\"\"\n",
    "    print(f\"🔄 Tri des données dans {file_name}...\")\n",
    "\n",
    "    # Chargement des données\n",
    "    try:\n",
    "        df = pd.read_csv(file_name, parse_dates=['timestamp'])\n",
    "        print(f\"✅ Données chargées : {len(df)} lignes.\")\n",
    "    except FileNotFoundError:\n",
    "        raise ValueError(f\"Fichier introuvable : {file_name}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise ValueError(f\"Fichier vide ou mal formaté : {file_name}\")\n",
    "    \n",
    "    # Vérification de la colonne de timestamp\n",
    "    if 'timestamp' not in df.columns:\n",
    "        raise ValueError(\"La colonne 'timestamp' est manquante dans le fichier.\")\n",
    "    \n",
    "    # Barre de progression pour simuler le tri\n",
    "    tqdm.pandas(desc=\"🔍 Tri des données\")\n",
    "    df.sort_values(by='timestamp', inplace=True)\n",
    "    print(\"✅ Tri effectué.\")\n",
    "    \n",
    "    # Réécrire les données triées dans le même fichier\n",
    "    print(f\"💾 Réécriture des données triées dans {file_name}...\")\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print(\"✅ Réécriture terminée.\")\n",
    "\n",
    "file_name = \"historical_data_eth_1M.csv\"\n",
    "\n",
    "sort_csv_in_place(file_name)\n",
    "\n",
    "print(f\"✅ Fichier trié et réécrit : {file_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Analyse du fichier historical_data_eth_1M.csv pour détecter les doublons...\n",
      "✅ Données chargées : 3835596 lignes.\n",
      "❌ 32847 doublons détectés.\n",
      "🔄 Suppression des doublons en cours...\n",
      "💾 Mise à jour du fichier CSV...\n",
      "✅ Doublons supprimés. Fichier mis à jour : historical_data_eth_1M.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\"\"\"\n",
    "on supprime les doublons, il analyse les timestamp et supprime les doublons\n",
    "\"\"\"\n",
    "\n",
    "def remove_duplicates(file_name):\n",
    "    \"\"\"\n",
    "    Analyse et supprime les doublons dans un fichier CSV basé sur l'index (timestamp).\n",
    "    Modifie directement le fichier fourni.\n",
    "\n",
    "    :param file_name: Chemin du fichier CSV à analyser et modifier.\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Analyse du fichier {file_name} pour détecter les doublons...\")\n",
    "    \n",
    "    try:\n",
    "        # Charger les données\n",
    "        df = pd.read_csv(file_name, parse_dates=['timestamp'], index_col='timestamp')\n",
    "        print(f\"✅ Données chargées : {len(df)} lignes.\")\n",
    "\n",
    "        # Identifier les doublons\n",
    "        duplicated = df.index.duplicated(keep='first')\n",
    "        num_duplicates = duplicated.sum()\n",
    "\n",
    "        if num_duplicates == 0:\n",
    "            print(\"✅ Aucun doublon détecté.\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"❌ {num_duplicates} doublons détectés.\")\n",
    "        \n",
    "        # Suppression des doublons avec une barre de progression\n",
    "        print(\"🔄 Suppression des doublons en cours...\")\n",
    "        df = df[~duplicated]\n",
    "        \n",
    "        # Réécrire le fichier original\n",
    "        print(\"💾 Mise à jour du fichier CSV...\")\n",
    "        df.to_csv(file_name)\n",
    "        print(f\"✅ Doublons supprimés. Fichier mis à jour : {file_name}\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Fichier introuvable : {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Une erreur est survenue : {e}\")\n",
    "\n",
    "file_name = \"historical_data_eth_1M.csv\"\n",
    "remove_duplicates(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ La base de données a 35 anomalies.\n",
      "Premières anomalies détectées :\n",
      "timestamp\n",
      "2017-09-06 23:00:00   0 days 07:00:00\n",
      "2017-12-04 06:49:00   0 days 00:49:00\n",
      "2017-12-18 10:14:00   0 days 00:14:00\n",
      "2017-12-18 13:34:00   0 days 01:05:00\n",
      "2018-01-04 05:06:00   0 days 02:06:00\n",
      "Name: timestamp, dtype: timedelta64[ns]\n",
      "🔍 Vérification de la complétude des données...\n",
      "📊 Total attendu : 3811381 timestamps\n",
      "📊 Total présent : 3802749 timestamps\n",
      "📊 Total manquant : 8632 timestamps\n",
      "📊 Complétude des données : 99.77%\n",
      "⏳ Temps total manquant : 5 jours, 23 heures, 52 minutes.\n",
      "📊 Total manquant en minutes : 8632\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# Verificer l'intégrité de la base de donnée\n",
    "###############################\n",
    "\n",
    "file_path = 'historical_data_eth_1M.csv'  # Chemin vers votre fichier CSV\n",
    "df = pd.read_csv(file_path, parse_dates=['timestamp'], index_col='timestamp')\n",
    "\n",
    "#############################\n",
    "# vérification de l'entièreté de la base de donnée \n",
    "############################\n",
    "expeted_interval = pd.Timedelta('1min')\n",
    "timestamp_diff = df.index.to_series().diff()\n",
    "\n",
    "anomalies = timestamp_diff[timestamp_diff != expeted_interval]\n",
    "\n",
    "# on exclus la première ligne comme une anomalie \n",
    "anomalies = timestamp_diff[1:][timestamp_diff[1:] != expeted_interval]\n",
    "\n",
    "# Afficher le résultat\n",
    "if anomalies.empty:\n",
    "    print(\"✅ La base de données est complète. Tous les timestamps respectent l'intervalle de 1 minute.\")\n",
    "else:\n",
    "    print(f\"❌ La base de données a {len(anomalies)} anomalies.\")\n",
    "    print(\"Premières anomalies détectées :\")\n",
    "    print(anomalies.head())\n",
    "\n",
    "#############################\n",
    "# afficher l'entièreté de la base de donnée en % \n",
    "#############################\n",
    "# plage complete attendue\n",
    "expected_index = pd.date_range(start=df.index.min(), end=df.index.max(), freq='1min')\n",
    "# calculer les stat \n",
    "total_expected = len(expected_index)\n",
    "total_present = len(df)\n",
    "total_missing = total_expected - total_present\n",
    "# ccalculer le pourcentage de complétude \n",
    "completeness_percentage = (total_present / total_expected) * 100\n",
    "# Afficher les résultats\n",
    "print(f\"🔍 Vérification de la complétude des données...\")\n",
    "print(f\"📊 Total attendu : {total_expected} timestamps\")\n",
    "print(f\"📊 Total présent : {total_present} timestamps\")\n",
    "print(f\"📊 Total manquant : {total_missing} timestamps\")\n",
    "print(f\"📊 Complétude des données : {completeness_percentage:.2f}%\")\n",
    "\n",
    "#############################\n",
    "# afficher le temps quil nous manque au totale \n",
    "#############################\n",
    "missing_timestamps = expected_index.difference(df.index)\n",
    "# Calculer le temps total manquant\n",
    "if not missing_timestamps.empty:\n",
    "    total_missing_time = missing_timestamps[-1] - missing_timestamps[0]\n",
    "    total_minutes_missing = len(missing_timestamps)  # Nombre total de minutes manquantes\n",
    "    days, remainder = divmod(total_minutes_missing, 1440)  # 1 jour = 1440 minutes\n",
    "    hours, minutes = divmod(remainder, 60)\n",
    "\n",
    "    # Afficher les résultats\n",
    "    print(f\"⏳ Temps total manquant : {days} jours, {hours} heures, {minutes} minutes.\")\n",
    "    print(f\"📊 Total manquant en minutes : {total_minutes_missing}\")\n",
    "else:\n",
    "    print(\"✅ Aucune donnée manquante. Le fichier est complet.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
