
# nouvelle version de la strat√©gie pr√©c√©dente 
# utilidation de moyenne mobile simple 
"""
/*****************************\
|*Indicateur utilis√© : SMA_X *|
\*****************************/

    * La strat√©gie repose sur l'utilisation d'une moyenne mobile simple (SMA_X) sur X p√©riodes comme principal indicateur.

    * La SMA_X est utilis√©e pour d√©terminer la tendance actuelle du march√© : lorsque le prix d√©passe cette moyenne,
    cela indique une possible tendance haussi√®re √† court terme, favorable √† une opportunit√© d'achat.
"""

import pandas as pd
import ta 
import numpy as np
import uuid
import matplotlib.pyplot as plt


# on r√©cup√®re la base de donn√©e 
def downloadDb(filaname):
    print("Start downloading data...")
    global START_DATE, END_DATE
    # on stocke les donn√©es dans un data frame on parse les dates et on les indexe
    df = pd.read_csv(filaname, parse_dates=['timestamp'], index_col='timestamp')
    # on filtre les donn√©es selon les dates 
    if START_DATE:
        df = df[df.index >= pd.Timestamp(START_DATE)]
    if END_DATE:
        df = df[df.index <= pd.Timestamp(END_DATE)]
    # on v√©rifie si la db est pas vide
    if df.empty:
        raise ValueError("No data available for the selected date range.")
    return df 

# on v√©rifie l'int√©grit√© de la base de donn√©e
def verify_db_integrity(df, freq):
    # Cr√©er un index complet bas√© sur les limites des timestamps
    complete_index = pd.date_range(start=df.index.min(), end=df.index.max(), freq=freq)
    # Identifier les timestamps manquants
    missing_timestamps = complete_index.difference(df.index)
    if missing_timestamps.empty:
        print("No missing timestamps.")
    else:
        print(f"Missing timestamps")

# on subdivise la base de donn√©e par date
def subdivide_db_by_date(df):
    print("Start subdividing db by name...")
    # grouper les donn√©es par jour
    grouped = df.groupby(pd.Grouper(freq='D'))
    # cr√©e un dictionnaire ou chaque clef est une date et chaque valeur est le DataFrame correspondant
    daily_data = {date: data for date, data in grouped}
    return daily_data

# supprime mes jours qui ne ont pas 1440 min ou tout le SMA_X de calcul√©
def remove_incomplete_days(daily_data):
    print("Start filtering daily_data...")
    filtered_data = {}
    removed_days = []
    for date, data in daily_data.items():
        if len(data) != 1440 or data['SMA_X'].isna().any():
            removed_days.append(date)  # Enregistrer les jours supprim√©s
        else:
            filtered_data[date] = data  # Conserver les jours complets
    return filtered_data

# v√©rifie l'int√©grit√© des donn√©es et affiche un print 
def verify_daily_data_integrity(daily_data):
    print("üîç V√©rification de l'int√©grit√© des donn√©es journali√®res...")
    issues_found = False  # Indicateur si des probl√®mes sont d√©tect√©s
    for date, data in daily_data.items():
        if len(data) == 1440:  # V√©rifier les jours complets
            missing_sma = data['SMA_X'].isna().sum()  # V√©rifier SMA_X manquant
            if missing_sma > 0:
                #print(f"‚ùå SMA_X incomplet pour le jour {date.date()} - {missing_sma} valeurs manquantes.")
                issues_found = True
        else:
            #print(f"‚ö†Ô∏è Jour {date.date()} ignor√© (donn√©es incompl√®tes, {len(data)} minutes).")
            issues_found = True
    if not issues_found:
        print("‚úÖ Toutes les donn√©es journali√®res sont compl√®tes et valides !")
    else:
        print(f"‚ùå Probl√®me d√©tect√© dans les donn√©es")

# on calcul la moyenne mobile simple sur X p√©riodes, et on supprime les p√©riode d√©fectueses 
def calculate_sma_x_on_daily_data(daily_data):
    # valeur globale du SMA qu'on √† d√©fini 
    global SMA_VALUE
    print("Start calculating SMA_X on daily data...")
    # Donn√©es pr√©c√©dentes
    previous_data = pd.DataFrame()
    skipped_days = 0
    processed_days = 0
    filtered_data = {}  # Stocker les jours valides avec SMA_X complet
    for date, data in daily_data.items():
        # Ajouter la colonne SMA_X avec des valeurs NaN par d√©faut
        data['SMA_X'] = np.nan
        # V√©rifier qu'il y a bien 1440 minutes dans la journ√©e
        if len(data) != 1440:
            #print(f"Skipping date {date}: insufficient data ({len(data)} minutes)")
            skipped_days += 1
            continue
        # Combiner les donn√©es pr√©c√©dentes avec celles du jour actuel
        combined_data = pd.concat([previous_data, data])
        # Calculer le SMA_X globalement
        combined_data['SMA_X'] = ta.trend.sma_indicator(combined_data['close'], window=SMA_VALUE)
        # V√©rifier si toutes les lignes actuelles ont un SMA_X calcul√©
        if combined_data['SMA_X'].loc[data.index].isna().any():
            #print(f"Skipping date {date}: incomplete SMA_X calculation.")
            skipped_days += 1
            # Mettre √† jour les donn√©es pr√©c√©dentes pour le prochain jour
            previous_data = data.tail(SMA_VALUE)
            continue
        # Appliquer les valeurs calcul√©es au DataFrame du jour actuel
        data['SMA_X'] = combined_data['SMA_X'].loc[data.index]
        filtered_data[date] = data  # Conserver uniquement les jours valides
        processed_days += 1
        # Mettre √† jour les donn√©es pr√©c√©dentes (20 derni√®res minutes)
        previous_data = data.tail(SMA_VALUE)
    print(f"SMA_X calculation completed. Processed days: {processed_days}, ‚ùå Skipped days: {skipped_days}")
    return filtered_data

# condition de achat 
def buy_condition(data_row):
    # si cette condition est bonne on retourne true, c'est la condition d'achat
    if data_row['close'] > data_row['SMA_X']:
        return True
    # la condition n'est pas bonne on retourne false
    return False

# condition de vente
def sell_condition(data_row, position):
    # temps max entre chaque tarsaction / trade 
    global MAX_WINDOW
    # current_time est la date actuelle
    current_time = data_row.name
    # V√©rifier si le prix atteint ou d√©passe le target_price
    if data_row['close'] >= position['target_price']:
        return True  # Vente r√©ussie √† l'objectif de profit
    # V√©rifier si la position est ouverte depuis plus de `window_size` minutes
    if (current_time - position['buy_date']).total_seconds() / 60 > MAX_WINDOW:
        return True  # Vente forc√©e apr√®s 60 minutes
    return False  # Pas de vente

# creation de transaction , √† chaque fois que on ach√®te on cr√©e cet √©l√©ment 
def create_transaction(buy_date, buy_price, quantity, buy_fee, target_price):
    return {
        "id": str(uuid.uuid4()), # ID unique pour chaque transaction
        "buy_date": buy_date,    # Date et heure d'achat
        "buy_price": buy_price,  # Prix d'achat
        "quantity": quantity,    # Quantit√© achet√©e
        "target_price": target_price, # prix cible
        "buy_fee": buy_fee,      # Frais d'achat
        "sell_fee": None,        # Frais de vente (sera mis √† jour lors de la vente)
        "sell_date": None,       # Date et heure de vente
        "sell_price": None,      # Prix de vente
        "profit": None           # Profit calcul√© apr√®s la vente
    }

# g√®re la transaction d'achat , donc ce que on avais avant dans la condition d'achat dans trade se retrouve ici 
def treat_buy_transaction(row, invest_amount, fee_rate, min_profit):
    global BALANCE
    #print(f"Buy condition met at {row.name}")
    # Calcul des frais d'achat
    buy_fee = invest_amount * fee_rate
    # Montant net apr√®s d√©duction des frais
    net_investment = invest_amount - buy_fee
    # Quantit√© calcul√©e en fonction du prix
    quantity = net_investment / row['close']
    # Calcul du prix cible (target_price)
    target_price = row['close'] * (1 + min_profit + 2 * fee_rate)
    # on met √† jour le solde
    BALANCE -= invest_amount
    # Cr√©ation d'une nouvelle transaction
    return create_transaction(row.name, row['close'], quantity, buy_fee, target_price)

# on traite la transaction de vente
def treat_sell_transaction(data_row, transaction, fee_rate):
    global BALANCE
    #print(f"Sell condition met at {data_row.name}")
    # Prix de vente
    sell_price = data_row['close']
    # Calcul des frais de vente
    sell_fee = sell_price * transaction['quantity'] * fee_rate
    # Montant net obtenu apr√®s la vente
    net_proceeds = sell_price * transaction['quantity'] - sell_fee
    # Calcul du profit
    profit = net_proceeds - (transaction['buy_price'] * transaction['quantity'] + transaction['buy_fee'])
    # Mise √† jour de la transaction
    transaction.update({
        "sell_fee": sell_fee,
        "sell_date": data_row.name,
        "sell_price": sell_price,
        "profit": profit,
    })
    # on met √† jour le solde
    BALANCE += net_proceeds

# print de compte rendu
def print_report(archived_transactions, transactions):
    # Valeur du portefeuille
    global BALANCE
    print(f"/Start de print de compte rendu.\\")
    # Frais
    total_buy_fee = archived_transactions['buy_fee'].sum()
    total_sell_fee = archived_transactions['sell_fee'].sum()
    total_fees = total_buy_fee + total_sell_fee
    print(f"Total frais d'achat : {total_buy_fee:.2f}")
    print(f"Total frais de vente : {total_sell_fee:.2f}")
    print(f"Total frais : {total_fees:.2f}")
    # Profits et soldes
    total_profit = archived_transactions['profit'].sum()
    print(f"Profit total : {total_profit:.2f}")
    print(f"Solde final : {BALANCE:.2f}")
    print(f"Nombre de transactions : {len(archived_transactions)}")

    # Transactions par ann√©e
    if 'sell_date' in archived_transactions:
        archived_transactions['sell_date'] = pd.to_datetime(archived_transactions['sell_date'])
        years = archived_transactions['sell_date'].dt.year.unique()
        avg_transactions_per_year = len(archived_transactions) / len(years)
        print(f"Transactions par ann√©e en moyenne : {avg_transactions_per_year:.2f}")
    else:
        print("Pas de dates de vente disponibles pour calculer les transactions par ann√©e.")

    # Calcul du temps moyen d'un trade
    archived_transactions['trade_duration'] = (
        (pd.to_datetime(archived_transactions['sell_date']) - 
         pd.to_datetime(archived_transactions['buy_date']))
        .dt.total_seconds() / 60
    )
    avg_trade_duration = archived_transactions['trade_duration'].mean()
    avg_days = int(avg_trade_duration // (24 * 60))
    avg_hours = int((avg_trade_duration % (24 * 60)) // 60)
    avg_minutes = int(avg_trade_duration % 60)
    print(f"Dur√©e moyenne d'un trade : {avg_days} jours, {avg_hours} heures, {avg_minutes} minutes ({avg_trade_duration:.2f} minutes)")

    # Temps moyen par ann√©e
    print("\nTemps moyen d'un trade par ann√©e :")
    archived_transactions['year'] = archived_transactions['buy_date'].dt.year
    for year, group in archived_transactions.groupby('year'):
        avg_duration_year = group['trade_duration'].mean()
        days = int(avg_duration_year // (24 * 60))
        hours = int((avg_duration_year % (24 * 60)) // 60)
        minutes = int(avg_duration_year % 60)
        print(f"  {year}: {days} jours, {hours} heures, {minutes} minutes ({avg_duration_year:.2f} minutes)")

    # Taux de r√©ussite
    winning_trades = archived_transactions[archived_transactions['profit'] > 0].copy()
    losing_trades = archived_transactions[archived_transactions['profit'] <= 0].copy()
    success_rate = len(winning_trades) / len(archived_transactions) * 100
    print(f"\nTaux de r√©ussite : {success_rate:.2f}% ({len(winning_trades)} gagnants, {len(losing_trades)} perdants)")

    # Gain moyen par transaction
    avg_profit_per_trade = archived_transactions['profit'].mean()
    print(f"Gain moyen par transaction : {avg_profit_per_trade:.2f} EUR")

    # Temps moyen des trades gagnants et perdants
    winning_trades['trade_duration'] = (
        (pd.to_datetime(winning_trades['sell_date']) - 
         pd.to_datetime(winning_trades['buy_date']))
        .dt.total_seconds() / 60
    )
    losing_trades['trade_duration'] = (
        (pd.to_datetime(losing_trades['sell_date']) - 
         pd.to_datetime(losing_trades['buy_date']))
        .dt.total_seconds() / 60
    )

    avg_winning_duration = winning_trades['trade_duration'].mean() if not winning_trades.empty else 0
    avg_losing_duration = losing_trades['trade_duration'].mean() if not losing_trades.empty else 0

    def format_duration(minutes):
        days = int(minutes // (24 * 60))
        hours = int((minutes % (24 * 60)) // 60)
        mins = int(minutes % 60)
        return f"{days} jours, {hours} heures, {mins} minutes"

    if not winning_trades.empty:
        print(f"Temps moyen des trades gagnants : {format_duration(avg_winning_duration)} ({avg_winning_duration:.2f} minutes)")
    else:
        print("Pas de trades gagnants.")

    if not losing_trades.empty:
        print(f"Temps moyen des trades perdants : {format_duration(avg_losing_duration)} ({avg_losing_duration:.2f} minutes)")
    else:
        print("Pas de trades perdants.")

    # Nombre de trades gagnants et perdants par ann√©e
    print("\nNombre de trades gagnants et perdants par ann√©e :")
    for year, group in archived_transactions.groupby('year'):
        wins = len(group[group['profit'] > 0])
        losses = len(group[group['profit'] <= 0])
        print(f"  {year}: {wins} gagnants, {losses} perdants")


# fonction de trading c'est ici on vas faire le backtest 
def trade(daily_data):
    # on utilise les variables globales
    global BALANCE, INVEST_AMOUNT, FEE, MAX_TRANSACTION, TARGET_PROFIT
    # print de d√©but de trading
    print("Start of trading...")
    # investement par trade
    invest_amount = INVEST_AMOUNT
    # buy and sell fee of 0.1% 
    fee_rate = FEE
    #min profit
    min_profit = TARGET_PROFIT
    # on vas stocker chaque transaction dans cette liste
    transactions = []  # Liste des transactions
    # transactions archiv√©s 
    archived_transactions = []  # Liste des transactions archiv√©es
    # on parcours les donn√©es
    for date, data in daily_data.items():
        # on parcour chaque ligne de la data
        for i, row in data.iterrows():
            # condition d'achat , si elle est vrai + on √† assez de cash + on a pas le max de transaction, on ach√®te 
            if len(transactions) < MAX_TRANSACTION and BALANCE >= INVEST_AMOUNT and buy_condition(row):
                # on cr√©e une nouvelle transaction
                new_transaction = treat_buy_transaction(row, invest_amount, fee_rate, min_profit)
                # si la nouvelle transaction est vrai on l'ajoute √† la liste des transactions
                if new_transaction:
                    transactions.append(new_transaction)
            # on passe √† travers chaque transaction
            for transaction in transactions[:]:
                # si la condition de vente est vrai 
                if sell_condition(row, transaction):
                    # on traite la transaction de vente
                    treat_sell_transaction(row, transaction, fee_rate)
                    # on ajoute la transaction √† la liste des transactions archiv√©es
                    archived_transactions.append(transaction)
                    # on retire la transaction de la liste des transactions
                    transactions.remove(transaction)
    # Cl√¥turer les transactions ouvertes restantes
    if transactions:
        print(f"Cl√¥ture de {len(transactions)} transactions ouvertes restantes au dernier prix disponible.")
        last_date = sorted(daily_data.keys())[-1]
        last_data = daily_data[last_date]
        last_row = last_data.iloc[-1]
        for transaction in transactions:
            treat_sell_transaction(last_row, transaction, fee_rate)
            archived_transactions.append(transaction)
        transactions.clear()

    # on converti les transactions archiv√©s en DataFrame, ceci sera plus facile √† manipuler plus tard 
    df_archived_transactions = pd.DataFrame(archived_transactions)
    print_report(df_archived_transactions, transactions)
    return 

# valeur du portefeuille
BALANCE = 100
# montant d'investissment syst√©matique
INVEST_AMOUNT = (BALANCE / 100) * 50
# frais de achat et de vente 
FEE = 0.001
# nombre de transaction maximum √† la fois
MAX_TRANSACTION = 6 
# profit recherch√© 
TARGET_PROFIT = 0.030
# temps max entre chaque tarsaction / trade
MAX_WINDOW = (60 * 24 * 90)
# valeur du SMA_X
SMA_VALUE = 650
# date de √©but 
START_DATE = "2020-01-01"
# date de fin
END_DATE = "2024-11-15"
# nom du fichier de la base de donn√©e
FILE_NAME = "1_min_eth_candles_01012017_15112024.csv"

def main():
    # on download la base de donn√©e 
    df = downloadDb(FILE_NAME)
    # verifier la db
    verify_db_integrity(df, '1min')
    # devide by name 
    daily_data = subdivide_db_by_date(df)
    # calculer la moyenne mobile simple sur 20 p√©riodes
    daily_data = calculate_sma_x_on_daily_data(daily_data)
    # on trade
    trade(daily_data)
    
if __name__ == "__main__":
    main()

"""
                    <<<<<***********************>>>>>
                    <<<<< Remarques importantes >>>>>
                    <<<<<***********************>>>>>

* Remarques importantes :

* Je vous conseille de mettre le code dans un fichier jupiter notebook pour une meilleur visualisation.

* Les valeur actuelles des variables sont le r√©sultat de mes propre test. 

* Je ne vous conseille en aucun cas de les utiliser tel quel, il faut les tester et les ajuster selon vos besoins.

* De plus je ne vous conseille pas non plus de les utiliser en production, c'est juste un exemple de backtest.

* Je ne conseille pas non plus de utiliser le bot en production, il n'a pas √©t√© test√© en production et il n'est pas s√©curis√© + la
strat√©gie n'est pas optimis√© et n'est pas garantie de fonctionner.

!! Ne utilisez pas se bot, ou cette strat√©gie elle ne sont en rien fond√©, ce projet est juste un passe temps et un projet personnel.!!

(Si vous avez des suggestions n'h√©sitez pas √† me les partager)

"""